{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6c7cc8d1-2335-4f36-869e-f5079061b2a6",
   "metadata": {},
   "source": [
    "from train_hyper_DSC_BAND6_14Nov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac9649-6648-4941-8634-75936026aa8b",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cab60-a8b6-4453-9ba6-35e96da65ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os, glob\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.ndimage import sobel\n",
    "import lpips\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "#import matlab.engine\n",
    "#eng = matlab.engine.start_matlab()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e3713-3a5d-4bc3-8694-57bf50a9ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d5f6e-95be-4206-9a60-846915f2d114",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15db2d2-d78d-4129-9485-70a8171d3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scc(sr, hr):\n",
    "    sr = sr.astype(np.float64)\n",
    "    hr = hr.astype(np.float64)\n",
    "    \n",
    "    if sr.ndim == 2:\n",
    "        sr_lap_x = sobel(sr, axis=1)\n",
    "        sr_lap_y = sobel(sr, axis=0)\n",
    "        sr_lap = np.sqrt(sr_lap_x**2 + sr_lap_y**2)\n",
    "\n",
    "        hr_lap_x = sobel(hr, axis=1)\n",
    "        hr_lap_y = sobel(hr, axis=0)\n",
    "        hr_lap = np.sqrt(hr_lap_x**2 + hr_lap_y**2)\n",
    "\n",
    "        scc_map = (sr_lap * hr_lap) / (np.sqrt(np.sum(sr_lap**2)) * np.sqrt(np.sum(hr_lap**2)))\n",
    "    else:\n",
    "        sr_lap = np.zeros(sr.shape)\n",
    "        hr_lap = np.zeros(hr.shape)\n",
    "        \n",
    "        for idim in range(sr.shape[2]):  # Loop over spectral bands\n",
    "            sr_lap_x = sobel(sr[:, :, idim], axis=1)\n",
    "            sr_lap_y = sobel(sr[:, :, idim], axis=0)\n",
    "            sr_lap[:, :, idim] = np.sqrt(sr_lap_x**2 + sr_lap_y**2)\n",
    "\n",
    "            hr_lap_x = sobel(hr[:, :, idim], axis=1)\n",
    "            hr_lap_y = sobel(hr[:, :, idim], axis=0)\n",
    "            hr_lap[:, :, idim] = np.sqrt(hr_lap_x**2 + hr_lap_y**2)\n",
    "\n",
    "        scc_map = np.sum(sr_lap * hr_lap, axis=2) / (np.sqrt(np.sum(sr_lap**2, axis=2)) * np.sqrt(np.sum(hr_lap**2, axis=2)))\n",
    "    \n",
    "    scc_value = np.sum(sr_lap * hr_lap)\n",
    "    scc_value /= np.sqrt(np.sum(sr_lap**2))\n",
    "    scc_value /= np.sqrt(np.sum(hr_lap**2))\n",
    "\n",
    "    return scc_value, scc_map\n",
    "\n",
    "\n",
    "\n",
    "loss_fn = lpips.LPIPS(net='alex') \n",
    "def calculate_lpips_bandwise(sr, hr, loss_fn):\n",
    "    lpips_bandwise = []\n",
    "    num_bands = sr.shape[2]  # shape (H, W, C) for image\n",
    "\n",
    "    for band in range(num_bands):\n",
    "        sr_band = torch.tensor(sr[:, :, band]).unsqueeze(0).unsqueeze(0).float() \n",
    "        hr_band = torch.tensor(hr[:, :, band]).unsqueeze(0).unsqueeze(0).float()\n",
    "        \n",
    "        lpips_value = loss_fn(sr_band, hr_band)\n",
    "        lpips_bandwise.append(lpips_value.item())\n",
    "\n",
    "    return np.mean(lpips_bandwise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef009659-cec3-44d7-abe7-cd981b7d8851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a92649-ea94-4e8f-be5c-4a744db5fa64",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a28c92-58bc-4491-b329-91c8d219339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_global_metrics(lr_files, hr_files):\n",
    "    all_intensity_values = []\n",
    "\n",
    "    for lr_file in lr_files:\n",
    "        corresponding_hr_file = lr_file.replace('_LR4', '')\n",
    "        if corresponding_hr_file in hr_files:\n",
    "            lr_image = sio.loadmat(lr_file)['radiance']\n",
    "            hr_image = sio.loadmat(corresponding_hr_file)['radiance']\n",
    "\n",
    "            all_intensity_values.append(lr_image.flatten())\n",
    "            all_intensity_values.append(hr_image.flatten())\n",
    "\n",
    "    all_intensity_values = np.concatenate(all_intensity_values)\n",
    "\n",
    "    global_min = np.min(all_intensity_values)\n",
    "    global_max = np.max(all_intensity_values)\n",
    "    global_mean = np.mean(all_intensity_values)\n",
    "    global_median = np.median(all_intensity_values)\n",
    "    global_std = np.std(all_intensity_values)  \n",
    "\n",
    "    return all_intensity_values, global_min, global_max, global_mean, global_median, global_std\n",
    "\n",
    "def convert_normalise_meanSTD(image, global_mean, global_std):\n",
    "    min, max = image.min(), image.max()\n",
    "    diff = max - min\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    image = (image - global_mean) / global_std\n",
    "    norm_min, norm_max = image.min().item(), image.max().item()\n",
    "    return image, min, max, diff, norm_min, norm_max\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8b7cb-f7c0-4237-b049-86a3c66590fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_patches(image, patch_size, stride=16):\n",
    "    img_h, img_w, bands = image.shape  \n",
    "    patch_h, patch_w = patch_size\n",
    "\n",
    "    patches = []\n",
    "    for i in range(0, img_h - patch_h + 1, stride):\n",
    "        for j in range(0, img_w - patch_w + 1, stride):\n",
    "            patch = image[i:i + patch_h, j:j + patch_w, :]  \n",
    "            patches.append(patch)\n",
    "    return np.array(patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ddbba-fae0-4445-a631-7877e679a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_patches(data_path, patch_size, BAND, global_mean=None, global_std=None):\n",
    "    lr_data, hr_data, global_mean, global_std = load_normalise_data(data_path, BAND, global_mean, global_std)\n",
    "\n",
    "    lr_patches = []\n",
    "    hr_patches = []\n",
    "    print(f'LR Data Shape: {lr_data.shape}' )\n",
    "    print(f'HR Data Shape: {hr_data.shape}')\n",
    "\n",
    "    for lr_img, hr_img in zip(lr_data, hr_data):\n",
    "        lr_img_patches = extract_patches(lr_img, patch_size)  # lr_img (spectral bands, H, W)\n",
    "        hr_img_patches = extract_patches(hr_img, (patch_size[0] * 4, patch_size[1] * 4), stride=64)\n",
    "        lr_patches.extend(lr_img_patches)\n",
    "        hr_patches.extend(hr_img_patches)\n",
    "\n",
    "    lr_patches = np.array(lr_patches)\n",
    "    hr_patches = np.array(hr_patches)\n",
    "\n",
    "    print(f'LR Patch Shape: {lr_patches.shape}')\n",
    "    print(f'HR Patch Shape: {hr_patches.shape}')\n",
    "    \n",
    "    return lr_patches, hr_patches, global_mean, global_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f4266-2cec-47b2-b98a-31cb607733d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_normalise_data(data_dir, BAND, global_mean=None, global_std=None):\n",
    "    lr_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('RADIANCE_cropped_hyper_LR4.mat') and BAND in f ])\n",
    "    hr_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('RADIANCE_cropped_hyper.mat') and BAND in f])\n",
    "\n",
    "    if global_mean is None or global_std is None:\n",
    "        all_intensity_values, global_min, global_max, global_mean, global_median, global_std = compute_global_metrics(lr_files, hr_files)\n",
    "        \"\"\"\n",
    "        output_csv = os.path.join(params.save_dir, params.save_prefix + '_global_metrics.csv')\n",
    "        with open(output_csv, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Metric\", \"Value\"])\n",
    "            writer.writerow([\"Global Min\", global_min])\n",
    "            writer.writerow([\"Global Max\", global_max])\n",
    "            writer.writerow([\"Global Mean\", global_mean])\n",
    "            writer.writerow([\"Global Median\", global_median])\n",
    "\n",
    "        #plot_global_histogram(all_intensity_values, global_min, global_max, global_mean, global_median, global_std)\n",
    "        \"\"\"    \n",
    "    print(f\"Using Global Mean: {global_mean}, Global Std: {global_std}\")\n",
    "\n",
    "    lr_data = []\n",
    "    hr_data = []\n",
    "\n",
    "    for lr_file in lr_files:\n",
    "        corresponding_hr_file = lr_file.replace('_LR4', '')\n",
    "        if corresponding_hr_file in hr_files:\n",
    "            lr_image = sio.loadmat(lr_file)['radiance']\n",
    "            hr_image = sio.loadmat(corresponding_hr_file)['radiance']\n",
    "\n",
    "            if len(lr_image.shape) == 2:\n",
    "                lr_image = lr_image[np.newaxis, :, :]\n",
    "            if len(hr_image.shape) == 2:\n",
    "                hr_image = hr_image[:, :, np.newaxis]\n",
    "\n",
    "            lr_image, lr_min, lr_max, lr_diff, lr_norm_min, lr_norm_max = convert_normalise_meanSTD(lr_image, global_mean, global_std)\n",
    "            hr_image, hr_min, hr_max, hr_diff, hr_norm_min, hr_norm_max = convert_normalise_meanSTD(hr_image, global_mean, global_std)\n",
    "\n",
    "            lr_data.append(lr_image)\n",
    "            hr_data.append(hr_image)\n",
    "\n",
    "    lr_data = np.array([img.numpy() for img in lr_data])\n",
    "    hr_data = np.array([img.numpy() for img in hr_data])        \n",
    "    return lr_data, hr_data, global_mean, global_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f704fa-f4cb-454c-be67-ed4d034427dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08df78d4-ca3a-4941-8c00-c208cc94400d",
   "metadata": {},
   "source": [
    "# Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505b3f8-c63f-4804-95f2-ce7a0be0d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_spectral_bands, depth_multiplier=1, upsample_scale=2, mode='bilinear'):\n",
    "        super(DSC, self).__init__()\n",
    "        \n",
    "        self.depthwise_conv = nn.Conv2d(in_channels=num_spectral_bands, \n",
    "                                        out_channels=num_spectral_bands * depth_multiplier,  \n",
    "                                        kernel_size=3,  \n",
    "                                        stride=1,\n",
    "                                        padding=1,\n",
    "                                        groups=num_spectral_bands,  \n",
    "                                        bias=False)\n",
    "        \n",
    "        self.pointwise_conv = nn.Conv2d(in_channels=num_spectral_bands * depth_multiplier, \n",
    "                                        out_channels=out_channels,  \n",
    "                                        kernel_size=1,  \n",
    "                                        bias=False)\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # shape (batch_size, num_spectral_bands, height, width)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.pointwise_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class S5_DSCR_S(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_spectral_bands, depth_multiplier=1, upsample_scale=2, mode='bilinear'):\n",
    "        super(S5_DSCR_S, self).__init__()\n",
    "        self.interpolation = nn.Upsample(scale_factor=upsample_scale, mode='bicubic', align_corners=False)\n",
    "        self.dsc_block = DSC(in_channels, out_channels, num_spectral_bands, depth_multiplier)\n",
    "\n",
    "    def forward(self, x, target_size=None):\n",
    "        interpolated = self.interpolation(x)\n",
    "        refined = self.dsc_block(interpolated)\n",
    "        \n",
    "        if target_size is not None:\n",
    "            interpolated = F.interpolate(interpolated, size=target_size, mode='bicubic', align_corners=False)\n",
    "            refined = F.interpolate(refined, size=target_size, mode='bicubic', align_corners=False)\n",
    "        else:\n",
    "            refined = F.interpolate(refined, size=interpolated.shape[2:], mode='bicubic', align_corners=False)\n",
    "        output = refined + interpolated\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304fd99-d1b9-447e-bc26-145706fff2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedDSC_2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_spectral_bands, depth_multiplier=1, num_layers=3, kernel_size=3):\n",
    "        super(ImprovedDSC_2, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            depthwise_conv = nn.Conv2d(\n",
    "                in_channels=num_spectral_bands,  \n",
    "                out_channels=num_spectral_bands * depth_multiplier,  \n",
    "                kernel_size=kernel_size,  \n",
    "                stride=1,\n",
    "                padding=kernel_size // 2, \n",
    "                groups=num_spectral_bands,  \n",
    "                bias=False\n",
    "            )\n",
    "            layers.append(depthwise_conv)\n",
    "            \n",
    "            pointwise_conv = nn.Conv2d(\n",
    "                in_channels=num_spectral_bands * depth_multiplier,  \n",
    "                out_channels=out_channels,  \n",
    "                kernel_size=1,  \n",
    "                bias=False\n",
    "            )\n",
    "            layers.append(pointwise_conv)\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "\n",
    "\n",
    "class S5_DSCR(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_spectral_bands, depth_multiplier=1, num_layers=3, kernel_size=3, upsample_scale=2):\n",
    "        super(S5_DSCR, self).__init__()\n",
    "        self.interpolation = nn.Upsample(scale_factor=upsample_scale, mode='bicubic', align_corners=False)\n",
    "        self.dsc_block = ImprovedDSC_2(in_channels, out_channels, num_spectral_bands, depth_multiplier, num_layers, kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        interpolated = self.interpolation(x)\n",
    "        refined = self.dsc_block(interpolated)\n",
    "        output = refined + interpolated\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e832c-e098-464a-85a8-b07cedd36a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb5e20-e1f4-4efb-8bdc-958350ac6bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125eda17-33df-4459-9c24-3aef1f215cb9",
   "metadata": {},
   "source": [
    "# Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dafc90-d446-4dbb-9c90-c256f2fd1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self,\n",
    "                nepochs = 100,\n",
    "                report_step = 5,\n",
    "                batch_size = 1,\n",
    "                validation = 0.3,\n",
    "                net_loss = 'MSE',\n",
    "                net_opt = 'Adam',\n",
    "                net_lr = 1e-2,\n",
    "                net_name = 'S5Net',\n",
    "                save_dir = '',\n",
    "                ftrain = '',\n",
    "                ftest = '',\n",
    "                fvalid = '',\n",
    "                pretrain='',\n",
    "                save_prefix=''):\n",
    "        self.nepochs = nepochs\n",
    "        self.report_step = report_step\n",
    "        self.batch_size = batch_size\n",
    "        self.validation = validation\n",
    "        self.net_loss = net_loss\n",
    "        self.net_opt = net_opt\n",
    "        self.net_lr = net_lr\n",
    "        self.net_name = net_name\n",
    "        self.save_dir = save_dir\n",
    "        self.ftrain = ftrain\n",
    "        self.ftest = ftest\n",
    "        self.fvalid = fvalid\n",
    "        self.pretrain=pretrain\n",
    "        self.save_prefix=save_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e3805-f9fb-4b89-8c3b-9ae59a921063",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.expanduser(\"~/data_sets/\")\n",
    "SAVE_DIR  = os.path.join(BASE_PATH, 'outputs')\n",
    "net_optimizer = 'Adam' # 'adadelta', 'adadelta'\n",
    "net_lr = 1e-3\n",
    "net_loss = 'MSE' #'L1norm'\n",
    "net_name = 'BAND4_hyper'\n",
    "SAVE_PREFIX = net_optimizer +'_lr'+ str(net_lr) +'_' + str(net_loss)+'_'+ net_name\n",
    "train_image_names = os.path.join(BASE_PATH, 'train_hyper')\n",
    "valid_image_names  = os.path.join(BASE_PATH, 'valid_hyper')\n",
    "test_image_names  = os.path.join(BASE_PATH, 'test_hyper')\n",
    "\n",
    "\n",
    "params = Arguments(\n",
    "    nepochs=50,\n",
    "    report_step=5,\n",
    "    batch_size=1,\n",
    "    validation=0.2,\n",
    "    net_loss = net_loss,\n",
    "    net_opt = net_optimizer,\n",
    "    net_lr = net_lr,\n",
    "    net_name= net_name,\n",
    "    save_dir=SAVE_DIR,\n",
    "    ftrain=train_image_names,\n",
    "    ftest=test_image_names,\n",
    "    fvalid=valid_image_names,\n",
    "    pretrain='',\n",
    "    save_prefix = SAVE_PREFIX\n",
    ")\n",
    "\n",
    "SAVE_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07a366-9bc5-4a43-be90-024df1bd9f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938274c9-8aea-4519-a8b4-6381fc2d0f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d36ab641-5bfe-42cd-a7b3-ddab0d4720d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da5c8037-93ba-445d-820d-3615d48d83dc",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a7a0c-2851-4f9f-85cf-17c66449eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62d8ed-7e2d-4433-be58-94ae6c3cb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(args.save_dir, args.save_prefix, \"results.csv\")\n",
    "\n",
    "def metric_s5net(model, test_loader, device, network_name, csv_filename= csv_file):\n",
    "    model.eval()\n",
    "    psnr_values, scc_values = [], []\n",
    "    ssim_values, lpips_values = [], []\n",
    "    lr_images, hr_images, sr_images = [], [], []\n",
    "    ii =0\n",
    "    with torch.no_grad():\n",
    "        for lr, hr in test_loader:\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            model = model.to(device)  \n",
    "            output = model(lr)  \n",
    "            \n",
    "            for i in range(output.shape[0]):\n",
    "                sr = output[i].cpu().numpy().squeeze()\n",
    "                hr_img = hr[i].cpu().numpy().squeeze()\n",
    "                lr_img = lr[i].cpu().numpy().squeeze()\n",
    "\n",
    "                # LPIPS (normalized to [-1, 1])\n",
    "                sr_lpips = 2 * sr - 1\n",
    "                hr_lpips = 2 * hr_img - 1\n",
    "                lpips_value = calculate_lpips_bandwise(sr_lpips, hr_lpips, loss_fn)\n",
    "\n",
    "                # normalize to [0, 1]\n",
    "                sr = (sr - sr.min()) / (sr.max() - sr.min())\n",
    "                hr_img = (hr_img - hr_img.min()) / (hr_img.max() - hr_img.min())\n",
    "                \n",
    "                psnr_value = psnr(hr_img, sr, data_range=1)  # [0, 1] range\n",
    "                scc_value, _ = scc(sr, hr_img)\n",
    "                ssim_value = ssim(hr_img, sr, data_range=1)  # [0, 1] range\n",
    "\n",
    "                psnr_values.append(psnr_value)\n",
    "                scc_values.append(scc_value)\n",
    "                ssim_values.append(ssim_value)\n",
    "                lpips_values.append(lpips_value)\n",
    "\n",
    "                lr_images.append(lr_img)\n",
    "                hr_images.append(hr_img)\n",
    "                sr_images.append(sr)\n",
    "\n",
    "                ii= ii+1\n",
    "\n",
    "                hr_reshaped = hr_img.reshape(hr_img.shape[0], -1).T  \n",
    "                pca = PCA(n_components=3)\n",
    "                pca.fit(hr_reshaped)  \n",
    "                \n",
    "                hr_pca = pca.transform(hr_reshaped).T.reshape(3, hr_img.shape[1], hr_img.shape[2])  \n",
    "                lr_reshaped = lr_img.reshape(lr_img.shape[0], -1).T\n",
    "                lr_pca = pca.transform(lr_reshaped).T.reshape(3, lr_img.shape[1], lr_img.shape[2])  \n",
    "                sr_reshaped = sr.reshape(sr.shape[0], -1).T\n",
    "                sr_pca = pca.transform(sr_reshaped).T.reshape(3, sr.shape[1], sr.shape[2])  \n",
    "                \n",
    "                lr_pca = (lr_pca - lr_pca.mean()) / lr_pca.std()\n",
    "                hr_pca = (hr_pca - hr_pca.mean()) / hr_pca.std()\n",
    "                sr_pca = (sr_pca - sr_pca.mean()) / sr_pca.std()\n",
    "\n",
    "                plot_hyperspectral_images_false_color_global2(lr_pca, hr_pca, sr_pca, ii, network_name, bands=[1,0, 2], cmap='viridis') \n",
    "\n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_scc = np.mean(scc_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    avg_lpips = np.mean(lpips_values)\n",
    "\n",
    "    print(f\"PSNR: {avg_psnr:.4f}\")\n",
    "    print(f\"SCC: {avg_scc:.4f}\")\n",
    "    print(f\"SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"LPIPS: {avg_lpips:.4e}\")\n",
    "\n",
    "    rounded_values = [\n",
    "    network_name,\n",
    "    round(avg_psnr, 4),\n",
    "    round(avg_scc, 4),\n",
    "    round(avg_ssim, 4),\n",
    "    f\"{avg_lpips:.4e}\"]\n",
    "\n",
    "    file_exists = os.path.isfile(csv_filename)\n",
    "    with open(csv_filename, mode='a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        if not file_exists:\n",
    "            csv_writer.writerow([\"Network Name\", \"PSNR\", \"SCC\", \"SSIM\", \"LPIPS\"])\n",
    "        csv_writer.writerow(rounded_values)\n",
    "    \n",
    "    return avg_psnr, avg_scc,  avg_ssim, avg_lpips, lr_images, hr_images, sr_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3761a6a-af2d-434c-8b18-60170bf5ef0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbcb52-c581-4498-a2eb-ba4701d0568e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af9f7c07-54d9-470b-90ad-711c7b7d65c6",
   "metadata": {},
   "source": [
    "## loader and paramters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee335-2013-4a29-ae80-66a059f360a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = params\n",
    "\n",
    "lr_patches, hr_patches, global_mean, global_std  = load_data_with_patches(args.ftrain, (64, 64), 'BAND4')\n",
    "\n",
    "\n",
    "lr_patches = lr_patches.transpose(0, 3, 1, 2)  # to (batch_size, channels, height, width)\n",
    "hr_patches = hr_patches.transpose(0, 3, 1, 2)\n",
    "\n",
    "train_data = [(torch.tensor(lr, dtype=torch.float32), torch.tensor(hr, dtype=torch.float32)) for lr, hr in zip(lr_patches, hr_patches)]\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True)\n",
    "    \n",
    "num_bands = lr_patches.shape[1]  # num of spectral channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4747b-6579-4133-8b88-664fb79e200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_patches, hr_patches,_ , _  = load_data_with_patches(params.fvalid, (64, 64), 'BAND4', global_mean=global_mean, global_std=global_std)\n",
    "    \n",
    "lr_patches = lr_patches.transpose(0, 3, 1, 2)  \n",
    "hr_patches = hr_patches.transpose(0, 3, 1, 2)\n",
    "\n",
    "valid_data = [(torch.tensor(lr, dtype=torch.float32), torch.tensor(hr, dtype=torch.float32)) for lr, hr in zip(lr_patches, hr_patches)]\n",
    "valid_loader = DataLoader(valid_data, batch_size=params.batch_size, shuffle=True)\n",
    "\n",
    "num_bands = lr_patches.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe30b9-9c16-43b0-ba4a-ce81f8d3cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_patches, hr_patches,_ , _  = load_data_with_patches(params.ftest, (64, 64), 'BAND4', global_mean=global_mean, global_std=global_std)\n",
    "    \n",
    "lr_patches = lr_patches.transpose(0, 3, 1, 2)  \n",
    "hr_patches = hr_patches.transpose(0, 3, 1, 2)\n",
    "\n",
    "test_data = [(torch.tensor(lr, dtype=torch.float32), torch.tensor(hr, dtype=torch.float32)) for lr, hr in zip(lr_patches, hr_patches)]\n",
    "test_loader = DataLoader(test_data, batch_size=params.batch_size, shuffle=False)\n",
    "\n",
    "num_bands = lr_patches.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c33b2f-13eb-44a3-9532-ce3c7978cd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67784f0c-b3f7-4c0f-9ea3-10d094370752",
   "metadata": {},
   "source": [
    "# S5_DSCR_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318fb87-8564-4fe3-8444-a700b15e5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S5_DSCR_S_train(args):\n",
    "    model = S5_DSCR_S(in_channels=num_bands, \n",
    "                            out_channels=497, \n",
    "                            num_spectral_bands=num_bands, \n",
    "                            depth_multiplier=1, \n",
    "                            upsample_scale=4, \n",
    "                            mode='convtranspose').to(device)  \n",
    "    \n",
    "    model = model.to(device)     \n",
    "    summary(model, input_size=(num_bands, 64, 64))\n",
    "\n",
    "    log_dir = os.path.join(args.save_dir, args.save_prefix, 'DSC')\n",
    "    writer_tensor = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    criterion = nn.L1Loss() if args.net_loss == 'L1norm' else nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.net_lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(args.nepochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (lr, hr) in enumerate(train_loader):\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(lr)\n",
    "            loss = criterion(output, hr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            if epoch % 2 == 0 and batch_idx == 0:  \n",
    "                for i in range(min(5, len(lr))):  \n",
    "                    lr_img = lr.cpu().numpy()[i]\n",
    "                    hr_img = hr.cpu().numpy()[i]\n",
    "                    pred_img = output.cpu().detach().numpy()[i]\n",
    "                    fig = plot_hyperspectral_images_false_color_train(lr_img, hr_img, pred_img, idx=epoch * len(train_loader) + batch_idx * len(lr) + i)\n",
    "                    writer_tensor.add_figure(f'Predictions vs Actuals/Epoch_{epoch}', fig, global_step=epoch * len(train_loader) + batch_idx * len(lr) + i)\n",
    "        \n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for lr, hr in valid_loader:\n",
    "                lr, hr = lr.to(device), hr.to(device)\n",
    "                output = model(lr)\n",
    "                val_loss += criterion(output, hr).item()\n",
    "\n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(valid_loader))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{args.nepochs}, Train Loss: {train_losses[-1]}, Validation Loss: {val_losses[-1]}\")\n",
    "        writer_tensor.add_scalar('Loss/Train', train_losses[-1], epoch)\n",
    "        writer_tensor.add_scalar('Loss/Validation', val_losses[-1], epoch)\n",
    "        scheduler.step(val_losses[-1])\n",
    "\n",
    "    writer_tensor.close()\n",
    "\n",
    "    try:\n",
    "        torch.save(model.state_dict(), os.path.join(args.save_dir, f\"{args.save_prefix}_DSC2_updated_hyperspectral_model.pth\"))\n",
    "        print('Model saved successfully.')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(args.save_dir, f\"{args.save_prefix}_DSC2_updated_losses.csv\"), mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Epoch\", \"Train Loss\", \"Validation Loss\"])\n",
    "            for epoch, (train_loss, val_loss) in enumerate(zip(train_losses, val_losses), 1):\n",
    "                writer.writerow([epoch, train_loss, val_loss])\n",
    "        print('Loss file saved successfully.')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving loss file: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166eedf-e607-44ec-9477-02bd8be61853",
   "metadata": {},
   "outputs": [],
   "source": [
    "S5_DSCR_S_train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e136b1b-90df-4124-a71e-0ba47eba7a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fc7ad-453b-4cae-a915-2d528e196cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S5_DSCR_S_test(params):\n",
    "    model = S5_DSCR_S(in_channels=num_bands, \n",
    "                            out_channels=497, \n",
    "                            num_spectral_bands=num_bands, \n",
    "                            depth_multiplier=1, \n",
    "                            upsample_scale=4, \n",
    "                            mode='convtranspose').to(device)  \n",
    "    \n",
    "    model.load_state_dict(torch.load(os.path.join(params.save_dir, f\"{params.save_prefix}_DSC2_updated_hyperspectral_model.pth\")))\n",
    "\n",
    "    avg_psnr, avg_scc, avg_ssim, avg_lpips, lr_images, hr_images, sr_images = metric_s5net(model, test_loader, device, 'S5_DSCR_S')\n",
    "    return lr_images, hr_images, sr_images\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29d690-62f4-4ae1-a2da-580d2bfc9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = S5_DSCR_S_test(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccda6c-e4c1-46d7-871b-682ed1e566bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3b7dda0-d103-4729-ab5c-1d7270204da8",
   "metadata": {},
   "source": [
    "# S5_DSCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897f961-2260-4032-b5eb-c1edbc51fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def S5_DSCR_train(args):\n",
    "    model = S5_DSCR(\n",
    "        in_channels=497,\n",
    "        out_channels=497,\n",
    "        num_spectral_bands=497,\n",
    "        depth_multiplier=3,\n",
    "        num_layers=5,\n",
    "        kernel_size=5,\n",
    "        upsample_scale=4)\n",
    "\n",
    "    model = model.to(device) \n",
    "    summary(model, input_size=(num_bands, 64, 64))\n",
    "\n",
    "    log_dir = os.path.join(args.save_dir, args.save_prefix, 'DSC_residual2')\n",
    "    writer_tensor = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    criterion = nn.L1Loss() if args.net_loss == 'L1norm' else nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.net_lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    \n",
    "    for epoch in range(args.nepochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (lr, hr) in enumerate(train_loader):\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(lr)\n",
    "            loss = criterion(output, hr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            if epoch % 2 == 0 and batch_idx == 0:  \n",
    "                for i in range(min(5, len(lr))):  \n",
    "                    lr_img = lr.cpu().numpy()[i]\n",
    "                    hr_img = hr.cpu().numpy()[i]\n",
    "                    pred_img = output.cpu().detach().numpy()[i]\n",
    "                    fig = plot_hyperspectral_images_false_color_train(lr_img, hr_img, pred_img, idx=epoch * len(train_loader) + batch_idx * len(lr) + i)\n",
    "                    writer_tensor.add_figure(f'Predictions vs Actuals/Epoch_{epoch}', fig, global_step=epoch * len(train_loader) + batch_idx * len(lr) + i)\n",
    "        \n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for lr, hr in valid_loader:\n",
    "                lr, hr = lr.to(device), hr.to(device)\n",
    "                output = model(lr)\n",
    "                val_loss += criterion(output, hr).item()\n",
    "\n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(valid_loader))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{args.nepochs}, Train Loss: {train_losses[-1]}, Validation Loss: {val_losses[-1]}\")\n",
    "        writer_tensor.add_scalar('Loss/Train', train_losses[-1], epoch)\n",
    "        writer_tensor.add_scalar('Loss/Validation', val_losses[-1], epoch)\n",
    "        scheduler.step(val_losses[-1])\n",
    "\n",
    "    writer_tensor.close()\n",
    "\n",
    "    try:\n",
    "        torch.save(model.state_dict(), os.path.join(args.save_dir, f\"{args.save_prefix}_DSC_residual2_updated_hyperspectral_model.pth\"))\n",
    "        print('Model saved successfully.')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(args.save_dir, f\"{args.save_prefix}_DSC_residual2_updated_losses.csv\"), mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Epoch\", \"Train Loss\", \"Validation Loss\"])\n",
    "            for epoch, (train_loss, val_loss) in enumerate(zip(train_losses, val_losses), 1):\n",
    "                writer.writerow([epoch, train_loss, val_loss])\n",
    "        print('Loss file saved successfully.')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving loss file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155dda3-75e5-4595-9a8c-2deddbeda687",
   "metadata": {},
   "outputs": [],
   "source": [
    "S5_DSCR_train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32102f-dc23-412f-8a39-27b35b7eb775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e98a78-c7ec-4695-9e07-7725bf5be5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def S5_DSCR_test(params):\n",
    "    model = S5_DSCR(\n",
    "        in_channels=497,\n",
    "        out_channels=497,\n",
    "        num_spectral_bands=497,\n",
    "        depth_multiplier=3,\n",
    "        num_layers=5,\n",
    "        kernel_size=5,\n",
    "        upsample_scale=4)\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(params.save_dir, f\"{params.save_prefix}_DSC_residual2_updated_hyperspectral_model.pth\")))\n",
    "    avg_psnr, avg_scc, avg_ssim, avg_lpips, lr_images, hr_images, sr_images = metric_s5net(model, test_loader, device,'S5_DSCR')\n",
    "    return lr_images, hr_images, sr_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a04f84-321c-483b-86ca-47222bc1b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = S5_DSCR_test(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69465c2-7d3c-4997-bb2a-ea60edd3f224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76bf717-ca80-4722-a1e3-c76078bbeac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed389c8a-0e5b-477e-bf5e-303721213f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3a372-744f-4c90-b6a3-49a45caddc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad7232-90ae-472d-a664-cd78a4f98a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ecb4a-23f4-45a3-ba83-8824a3b28dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa2ce8-a430-4cbd-8609-69f427f4ff5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f61311-81d8-45b4-b5e0-8facda5bf34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449d1b0-2ab0-479e-a0f5-7d6a12fb2e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa21962e-b337-4123-acb2-cf50f34b25e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21cde4-b367-4a81-89fc-277bba0b518c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
